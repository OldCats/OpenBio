{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83d4d240",
      "metadata": {},
      "source": [
        "# Image processing using FreeSurfer\n",
        "<hr/>\n",
        "***As-Is Software Disclaimer***\n",
        "\n",
        "This content in this repository is delivered “As-Is”. Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n",
        "\n",
        "<hr/>\n",
        "\n",
        "This notebook demonstrates usage of the Image Processing package <a href=\"https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferWiki\">FreeSurfer</a> in the IMAGE_PROCESSING flavor of JupyterLab on the DNAnexus platform.\n",
        "\n",
        "<a href=\"https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md\">MIT License</a> applies to this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99045bc",
      "metadata": {},
      "source": [
        "## 1. Preparing your environment\n",
        "### Launch spec:\n",
        "\n",
        "* App name: JupyterLab with Python, R, Stata, ML, Image Processing\n",
        "* App flavor: IMAGE_PROCESSING\n",
        "* Kernel: Python\n",
        "* Instance type: mem1_ssd1_v2_x16\n",
        "* Runtime: =~ 30 min\n",
        "* Data description: Input for this notebook is a T1-weighted MRI image. We are downloading the primer example data from <a href=\"https://www.fmrib.ox.ac.uk/primers/intro_primer/ExBox13/IntroBox13.html\">Oxford NeuroImaging Primer</a>. The downloaded zipped folder (size ~30 MB) contains the following images: \n",
        "    * Original (non-brain-extracted) structural image: `T1.nii.gz`\n",
        "    * Two brain extracted images: `T1_v1_brain.nii.gz` and `T1_v2_brain.nii.gz`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619dbe9b",
      "metadata": {},
      "source": [
        "### FreeSurfer License\n",
        "\n",
        "In order to use FreeSurfer, we need to generate a license and add it to the FreeSurfer Home directory. The license key registry page is <a href=\"https://surfer.nmr.mgh.harvard.edu/registration.html\">here</a>.\n",
        "\n",
        "Generate the license and upload it to the platform. Before running this notebook, download the license in the `FREESURFER_HOME` directory by running the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693b1fcb",
      "metadata": {},
      "outputs": [],
      "source": [
        "! dx download license.txt -o $FREESURFER_HOME\n",
        "\n",
        "### Alternatively, replace xxxx by project id and yyyy by file id\n",
        "### of the license file and run this:\n",
        "# dx download project-xxxx:file-yyyy -o $FREESURFER_HOME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45cf955",
      "metadata": {},
      "source": [
        "## 2. Download and Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aaadc07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download ExBox data\n",
        "! wget https://www.fmrib.ox.ac.uk/primers/intro_primer/ExBox13/ExBox13.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4201322",
      "metadata": {},
      "source": [
        "Alternatively, we can also use DICOM images to run these analyses. To do so, we can download DICOM images from the FreeSurfer tutorial dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbc96b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! wget -r --no-parent https://surfer.nmr.mgh.harvard.edu/pub/data/tutorial_data/practice_with_data/dicoms/\n",
        "# ! dx download -r dicoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5235a42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unzip ExBox data\n",
        "! apt-get update\n",
        "! apt-get install unzip\n",
        "! unzip ExBox13.zip\n",
        "! ls ExBox13/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb66b86f",
      "metadata": {},
      "source": [
        "## 3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c4f4a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nipype.interfaces import freesurfer\n",
        "from nipype.interfaces.freesurfer import ReconAll\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d5c22cc",
      "metadata": {},
      "source": [
        "## 4. Run `recon-all`\n",
        "Running all the reconstruction steps of `recon-all` can take several hours, as mentioned in the <a href=\"https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all#Step-wiseDirectives-1\"> recon-all documentation</a>. Here, we run only the motion correction directive `autorecon1`, which takes ~ 15-25 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c648ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "subject_dir = \"ExBox13\"\n",
        "if not os.path.exists(subject_dir):\n",
        "    os.mkdir(subject_dir)\n",
        "sub = \"Subj001\"\n",
        "reconall = ReconAll()\n",
        "reconall.inputs.subject_id = sub\n",
        "reconall.inputs.directive = \"autorecon1\"\n",
        "reconall.inputs.subjects_dir = subject_dir\n",
        "reconall.inputs.T1_files = \"ExBox13/T1.nii.gz\"\n",
        "print(reconall.cmdline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5dbfb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "reconall.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe2ae68",
      "metadata": {},
      "source": [
        "## 5. Visualize results of `autorecon1`\n",
        "### Load the input and out images\n",
        "The `nib.load()` function returns an nibabel object and allows us to get metadata about the MRI image without loading the actual image into memory. The nibabel object generated above does not load the actual image data. We use the `get_fdata()` function to load the image array data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a41b21b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input T1 file\n",
        "t1 = nib.load(\"ExBox13/T1.nii.gz\").get_fdata()\n",
        "\n",
        "# Motion corrected image\n",
        "motion_cor = nib.load(\"ExBox13/Subj001/mri/orig.mgz\").get_fdata()\n",
        "\n",
        "# Non-uniform Intensity corrected image\n",
        "nu_intensity_cor = nib.load(\"ExBox13/Subj001/mri/orig_nu.mgz\").get_fdata()\n",
        "\n",
        "# Normalized image\n",
        "normalized = nib.load(\"ExBox13/Subj001/mri/T1.mgz\").get_fdata()\n",
        "\n",
        "# Brainmask\n",
        "brainmask = nib.load(\"ExBox13/Subj001/mri/brainmask.auto.mgz\").get_fdata()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "675f7c92",
      "metadata": {},
      "source": [
        "### Plot the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1abf92d",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 5, figsize=(30, 10))\n",
        "\n",
        "fig.suptitle(\"Reconall- Autorecon1\", fontsize=14)\n",
        "ax[0].imshow(t1[:, 100, :], cmap=\"gray\")\n",
        "ax[0].set_title(\"Input T1 image\")\n",
        "\n",
        "ax[1].imshow(motion_cor[..., 100], cmap=\"gray\")\n",
        "ax[1].set_title(\"Motion corrected image\")\n",
        "\n",
        "ax[2].imshow(nu_intensity_cor[..., 100], cmap=\"gray\")\n",
        "ax[2].set_title(\"Non-uniform intensity corrected image\")\n",
        "\n",
        "ax[3].imshow(normalized[..., 100], cmap=\"gray\")\n",
        "ax[3].set_title(\"Normalized image\")\n",
        "\n",
        "ax[4].imshow(brainmask[..., 100], cmap=\"gray\")\n",
        "ax[4].set_title(\"Skullstripped image\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
