{
  "metadata": {
    "kernelspec": {
      "display_name": "Bash",
      "language": "bash",
      "name": "bash"
    },
    "language_info": {
      "codemirror_mode": "shell",
      "file_extension": ".sh",
      "mimetype": "text/x-sh",
      "name": "bash"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Common Somatic Tertiary Analysis (COSTA) Notebooks\n\nThis series of notebooks is created to common tertiary analysis of somatic genetic variants. The series consists of the following notebooks:\n\n- Notebook 0: Somatic Variant Source Data (not in OpenBio)\n- Notebook 1: Somatic VCF to annotated MAF\n- Notebook 2: Kaplan-Meier Survival Curve: Phenotype Based Cohort\n- Notebook 3: Population Level Somatic Mutation Analysis\n- Notebook 4: Kaplan-Meier Survival Curve: Somatic Variant Based Cohort\n- Notebook 5: Gene Level Somatic Mutation Analysis",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Notebook 1: Somatic VCF to annotated MAF\nIn this notebook, we download individual level VCF files saved in our project on the DNAnexus platform in the folder `source_vcf`, transform them into individual MAF files and save them in a folder on the platform. MAF files are annotated with transcript information from the VEP annotation database.\n\n<a href=\"https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md\">MIT License</a> applies to this notebook.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Preparing your environment\n### Launch spec:\n\n* App name: JupyterLab with Python, R, Stata, ML\n* Kernel: Bash\n* Instance type: mem1_ssd1_v2_x16\n* Runtime: =~ 55 min\n* Data description: File inputs for this notebook are:\n\n    * Individual level VCF files.\n    \n### Package and tools dependency:\n\n| Package | License | \n| --- | --- |\n| <a href=\"http://www.htslib.org/\">samtools</a> | <a href=\"https://github.com/dnanexus/OpenBio/blob/master/LICENSE.md\">MIT/Expat License</a> |\n| <a href=\"http://www.htslib.org/doc/tabix.html\">tabix</a> | <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache License 2.0</a> |\n| <a href=\"https://github.com/mskcc/vcf2maf\">VCF2MAF</a> | <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache License 2.0</a> |\n| <a href=\"https://www.ensembl.org/vep\">Ensembl-VEP</a> | <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache License 2.0</a> |",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Download Packages\n\nUncomment the install commands if you are comfortable with the library license and want to install and run the parts notebook that depend on the library.\n\n_Note: Package installation takes ~35 minutes_",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Ensembl-vep**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Install and update the dependencies of ensembl-vep. Uncomment to install\n# apt-get update\n# apt-get install cpanminus -y\n# apt-get install libmysqlclient-dev -y\n# cpanm DBI\n# cpanm DBD::mysql",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Download and install ensembl-vep. Uncomment to install\n# git clone https://github.com/Ensembl/ensembl-vep.git\n# cd ensembl-vep\n# perl INSTALL.pl --ASSEMBLY GRCh38 --AUTO aflc --SPECIES homo_sapiens -c /opt/notebooks/vep -n \n# cd ..",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Samtools**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Download Samtools. Uncomment to download\n# wget -q https://github.com/samtools/samtools/releases/download/1.15/samtools-1.15.tar.bz2",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Tabix**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Download tabix. Uncomment to download\n# wget -q https://github.com/samtools/htslib/releases/download/1.15/htslib-1.15.tar.bz2",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**VCF2MAF**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Download and vcf2maf. Uncomment to install\n# export VCF2MAF_URL=`curl -sL https://api.github.com/repos/mskcc/vcf2maf/releases | grep -m1 tarball_url | cut -d\\\" -f4`\n# curl -L -o mskcc-vcf2maf.tar.gz $VCF2MAF_URL; tar -zxf mskcc-vcf2maf.tar.gz; cd mskcc-vcf2maf-*\n# perl maf2vcf.pl --man\n# cd ..",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "_Note: At this point, we suggest creating a snapshot of the environment for resuse --> DNAnexus/Create SnapshotOnce a snapshot is created, the object may be used when launching a new JupyterLab instance and will contain all installed packages and any downloaded data._",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Install downloaded packages",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Samtools. Uncomment to install\n# tar -xf samtools-1.15.tar.bz2\n# cd samtools-1.15\n# ./configure --prefix=/where/to/install\n# make\n# make install\n# export PATH=/where/to/install/bin:$PATH\n# cd ..",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Tabix. Uncomment to install\n# tar -xf htslib-1.15.tar.bz2\n# cd htslib-1.15\n# ./configure --prefix=/where/to/install\n# make\n# make install\n# export PATH=/where/to/install/bin:$PATH\n# cd ..",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Pre-process source data\n\nIn this notebook, we will convert 50 VCF files to their corresponding MAF files.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dx ls source_vcf | head -50 > vcf_names_50.txt",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Change Chromosome Notation.**\n\nWhen working with additional VCF files, make sure to follow \"CHROM\" naming guidelines specified by vcf2maf. For example, vcf2maf supports the chromosome naming, \"1,\" instead of \"chr1.\" Any unmapped contigs (e.g. 11_KI270927v1_alt) should be filtered out before running VCF2MAF. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mkdir vcf_without_chr\n\nwhile read p; do\n    awk '{gsub(/^chr/,\"\"); print}' \"/mnt/project/source_vcf/\"\"$p\" > vcf_without_chr/\"$p\"\ndone < vcf_names_50.txt",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Run VCF2MAF\n\nWe need to obtain the tumor sample ID and normal sample ID from the VCF for converting it to MAF file. In our VCF files, the normal sample ID appears in the last column of the header and the tumor sample ID appears in the last-but-one column of the header.\n\nThe parameter `--vep-forks` gives the number of forked processes to use when running VEP. The maximum number of forked processes that you can have depends on the instance size. For the default instance size (mem1_ssd1_v2_x16), we recommend having 16 forks, where the fork count is equal to, or less than, the core suffix count (\"x16\"). For instance type naming conventions, see https://documentation.dnanexus.com/developer/api/running-analyses/instance-types.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Move vep cache to $HOME/.vep\nmv /opt/notebooks/vep/ $HOME/.vep/\n\ncd vcf_without_chr\n\n# Make a directory for individual MAF files\nmkdir ../individual_maf_files_50\n\n# Convert VCF to MAF\nfor vcf_file in TCGA-*.vcf; do \n    echo \"$vcf_file\"\n    vcf_fn=\"${vcf_file%.*}\"\n    colnames=($(cat \"$vcf_file\" | grep \"#CHROM\"))\n    tumor_id=${colnames[-2]}\n    normal_id=${colnames[-1]}\n    perl ../mskcc-vcf2maf-754d68a/vcf2maf.pl --input-vcf \"$vcf_file\" \\\n    --output-maf ../individual_maf_files_50/\"$vcf_fn\".maf \\\n    --ref-fasta $HOME/.vep/homo_sapiens/106_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz \\\n    --vep-path ../ensembl-vep \\\n    --ncbi-build GRCh38 \\\n    --tumor-id $tumor_id \\\n    --normal-id $normal_id \\\n    --vep-forks 16\n    rm \"$vcf_file\"\ndone\ncd ..",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## 5. Upload the results to the platform\nWe upload the `individual_maf_files_50` folder using `dx upload -r` command.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dx upload -r individual_maf_files_50",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
